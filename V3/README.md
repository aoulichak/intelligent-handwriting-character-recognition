# Intelligent Character Recognition (ICR) - Version 3.0 (TensorFlow Edition)

Version 3.0 represents a complete architectural overhaul of the ICR system. This version migrates the deep learning backend from **PyTorch** to **TensorFlow/Keras** to leverage its high-level API for rapid prototyping and deployment. It also introduces a robust "Data Fusion" pipeline that aggregates multiple heterogeneous datasets into a single, unified training tensor.

## Key Innovations in V3.0

* **Framework Migration**: Complete transition to **TensorFlow 2.x / Keras**.
* **Data Fusion Pipeline**: Merges three distinct data sources into a massive, unified dataset:
    1.  **Google Drive Dataset**: Raw 28x28 images.
    2.  **Kaggle A-Z Dataset**: CSV-based pixel data.
    3.  **EMNIST Letters**: Torchvision dataset (converted to TF tensors).
* **Robust Preprocessing**: Standardizes distinct data formats (CSV, PNG, Tensors) into a single normalized distribution before training.

## Project Structure

| File Name | Description |
| :--- | :--- |
| **ICR_V3.ipynb** | **Data Fusion & Training**<br>This Jupyter Notebook implements the complex ETL (Extract, Transform, Load) pipeline. It ingests data from all three sources, performs normalization, fuses them into a single dataset, and trains a Keras CNN model. |
| **icr_gui_app_v3.py** | **V3 Interface**<br>The graphical interface rewritten to support the TensorFlow backend. It manages the TensorFlow session, suppresses unnecessary logs, and performs inference using the Keras model. |
| **model_v3.h5** | **The Keras Model**<br>*(Generated by the notebook)* The saved Keras model file containing the architecture and weights. |

## Prerequisites

This version requires a different technology stack than V1/V2. Ensure you have the following installed:

* **TensorFlow** (2.x)
* **PyQt5**
* **NumPy**
* **Pillow** (PIL)
* **Matplotlib** (for notebook visualizations)

## Usage Instructions

### 1. Training (The Fusion Pipeline)
To execute the data fusion and training process:
1.  Open **ICR_V3.ipynb** in Jupyter or Google Colab.
2.  Ensure access to all three data sources (Drive path, Kaggle CSV, internet for EMNIST).
3.  Run the notebook cells to ingest, visualize, and merge the data.
4.  The training process will generate a Keras model file (typically `.h5` or `.keras` format).

### 2. Running the V3 Application
To use the TensorFlow-powered interface:
1.  Place the generated model file in the project root.
2.  Update the model path in `icr_gui_app_v3.py` if necessary.
3.  Execute the application:

```bash
python icr_gui_app_v3.py
```

The application window will appear, offering the same drawing and upload capabilities as previous versions, but powered by the new TensorFlow backend.

## Model Architecture (V3)
The model is a **Sequential Keras CNN** optimized for the fused dataset:
* **Input**: 28x28x1 Grayscale tensors.
* **Convolutional Layers**: Feature extraction with ReLU activation.
* **Pooling**: MaxPooling layers to reduce spatial dimensions.
* **Classification**: Dense (Fully Connected) layers with Softmax output for 26 classes.

## Acknowledgments
* **Claude Sonnet 4.5**: Development assistance, code migration to TensorFlow, and documentation support provided by Claude Sonnet 4.5.
